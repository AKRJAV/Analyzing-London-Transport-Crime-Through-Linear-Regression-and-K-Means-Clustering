# -*- coding: utf-8 -*-
"""22058372-DM-ML_CW

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16MQtDcEmA1iGxl2LriSr6KqqY540U3bs
"""

import pandas as pd
data = pd.read_csv('tfl_crime.csv')
data = data[['YEAR','MONTH_NO','BUS_CRIMES','UG-DLR_CRIMES','OG_CRIMES','TL_CRIMES','TFL_RAIL_CRIMES','TOTAL_CRIMES']]
data.info()

data1 = data.dropna(subset=['TFL_RAIL_CRIMES']).drop('TFL_RAIL_CRIMES', axis=1)
data1.head(5)

import seaborn as sns
data = data.drop('TFL_RAIL_CRIMES', axis=1)
sns.heatmap(data.corr(),cmap='YlGnBu',annot=True)

sns.pairplot(data,x_vars=['BUS_CRIMES','UG-DLR_CRIMES','OG_CRIMES','TL_CRIMES','YEAR','MONTH_NO'],y_vars='TOTAL_CRIMES',kind='scatter')

import pandas as pd
import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import numpy as np

# Load the data
data = pd.read_csv('tfl_crime.csv')
data = data[['YEAR', 'MONTH_NO','BUS_CRIMES','UG-DLR_CRIMES','OG_CRIMES','TL_CRIMES','TOTAL_CRIMES']]

# Define variables
variables = ['BUS_CRIMES','UG-DLR_CRIMES','OG_CRIMES','TL_CRIMES']

# Iterate over each variable and create OLS model
for col in variables:
    X = data[[col]]
    y = data['TOTAL_CRIMES']

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)
    X_train_sm = sm.add_constant(X_train)
    model = sm.OLS(y_train, X_train_sm).fit()

    # Calculate R-squared
    r_squared = model.rsquared

    # Make predictions
    y_pred = model.predict(X_train_sm)

    # Calculate RMSE
    rmse = np.sqrt(mean_squared_error(y_train, y_pred))

    # Print the OLS summary report with R-squared and RMSE
    print(f"OLS Summary Report for TOTAL_CRIMES vs {col}:")
    print(model.summary())
    print(f"R-squared: {r_squared:.2f}")
    print(f"RMSE: {rmse:.2f}")
    print("\n")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import numpy as np

# Load the data
data = pd.read_csv('tfl_crime.csv')
data = data[['YEAR', 'MONTH_NO', 'BUS_CRIMES','UG-DLR_CRIMES','OG_CRIMES','TL_CRIMES','TOTAL_CRIMES']]

# Define variables
variables = ['BUS_CRIMES','UG-DLR_CRIMES','OG_CRIMES','TL_CRIMES']
num_vars = len(variables)
num_rows = (num_vars + 1) // 2
num_cols = 2

# Create a figure with the determined number of rows and columns of subplots
fig, axs = plt.subplots(num_rows, num_cols, figsize=(12, 6 * num_rows))

# Flatten the axis array for easier indexing
axs = axs.flatten()

# Iterate over each subplot and create a scatter plot with a regression line
for i, col in enumerate(variables):
    X = data[[col]]
    y = data['TOTAL_CRIMES']

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)
    X_train_sm = sm.add_constant(X_train)
    model = sm.OLS(y_train, X_train_sm).fit()

    # Calculate R-squared
    r_squared = model.rsquared

    # Make predictions
    y_pred = model.predict(X_train_sm)

    # Calculate RMSE
    rmse = np.sqrt(mean_squared_error(y_train, y_pred))

    axs[i].scatter(X_train, y_train, alpha=0.5)
    axs[i].plot(X_train, model.predict(X_train_sm), 'r', label=f'Regression Line: y = {model.params[1]:.2f}x + {model.params[0]:.2f}')
    axs[i].set_title(f'TOTAL_CRIMES vs {col}\nR-squared: {r_squared:.2f}, RMSE: {rmse:.2f}',fontweight='bold')
    axs[i].set_xlabel(col,fontweight='bold')
    axs[i].set_ylabel('TOTAL_CRIMES',fontweight='bold')
    axs[i].legend(loc='upper right')

# Hide any remaining empty subplots
for j in range(num_vars, len(axs)):
    axs[j].axis('off')

# Adjust the spacing between subplots
plt.subplots_adjust(hspace=0.5, wspace=0.5)

# Display the figure
plt.show()

import pandas as pd
import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import numpy as np

# Load the data
data = pd.read_csv('tfl_crime.csv')

# Drop rows where TFL_RAIL has missing values
data = data[data['TFL_RAIL_CRIMES'].notnull()]

# Define variables
X = data['TFL_RAIL_CRIMES']
y = data['TOTAL_CRIMES']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=25)

# Add a constant to X_train for OLS regression
X_train_sm = sm.add_constant(X_train)

# Fit the OLS regression model
model = sm.OLS(y_train, X_train_sm).fit()

# Calculate R-squared
r_squared = model.rsquared

# Make predictions
y_pred = model.predict(X_train_sm)

# Calculate RMSE
rmse = np.sqrt(mean_squared_error(y_train, y_pred))

# Print the OLS summary report with R-squared and RMSE
print("OLS Summary Report for TOTAL_CRIMES vs TFL_RAIL:")
print(model.summary())
print(f"R-squared: {r_squared:.2f}")
print(f"RMSE: {rmse:.2f}")
print("\n")

# Create a figure and axis
fig, ax = plt.subplots(figsize=(8, 6))

# Plot the scatter plot and regression line
ax.scatter(X_train, y_train, alpha=0.5)
ax.plot(X_train, model.predict(X_train_sm), 'r', label=f'Regression Line: y = {model.params[1]:.2f}x + {model.params[0]:.2f}')
ax.set_title(f'TOTAL_CRIMES vs TFL_RAIL\nR-squared: {r_squared:.2f}, RMSE: {rmse:.2f}',fontweight='bold')
ax.set_xlabel('TFL_RAIL_CRIMES',fontweight='bold')
ax.set_ylabel('TOTAL_CRIMES',fontweight='bold')
ax.legend(loc='upper right')

# Display the figure
plt.show()

import matplotlib.pyplot as plt
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('tfl_crime.csv')
df = df[['YEAR','MONTH_NO','BUS_CRIMES','UG-DLR_CRIMES','OG_CRIMES','TL_CRIMES','TOTAL_CRIMES']]
scaled_df = StandardScaler().fit_transform(df)

kmeans_kwargs =  {
    "init" : "random",
    "n_init" : 10,
    "random_state" : 1
}

sse = [ ]

for k in range(1,11):
    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)
    kmeans.fit(scaled_df)
    sse.append(kmeans.inertia_)

plt.plot(range(1,11), sse)
plt.xticks(range(1,11))
plt.title('Elbow Method for Optimal K value',fontweight='bold')
plt.xlabel('Number of Clusters',fontweight='bold')
plt.ylabel('SSE',fontweight='bold')
plt.show()

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

df = df[['BUS_CRIMES','UG-DLR_CRIMES']]
kmeans = KMeans(n_clusters=3)
kmeans.fit(df)

labels = kmeans.labels_
centroids = kmeans.cluster_centers_
label_names = ['Cluster1','Cluster2','Cluster3']

# Define the colors for each label using the 'brg' colormap
colors = ['b', 'r', '#90EE90']

for label in range(len(label_names)):
    cluster_data = df[labels == label]
    plt.scatter(cluster_data['BUS_CRIMES'], cluster_data['UG-DLR_CRIMES'], c=colors[label], label=label_names[label])

plt.scatter(centroids[:,0], centroids[:,1], marker='x', s=150, c='black', label='Centroids')
plt.xlabel('London Bus',fontweight='bold')
plt.ylabel('London Underground / Docklands Light Railway',fontweight='bold')
plt.title('K-Means Clustering of Higher Crime Modes for k=3',fontweight='bold')
plt.legend(loc='upper right',fontsize='medium')
plt.show()

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

data1 = pd.read_csv('tfl_crime.csv')
data1 = data1[['OG_CRIMES','TL_CRIMES']]
kmeans = KMeans(n_clusters=3)
kmeans.fit(data1)

labels = kmeans.labels_
centroids = kmeans.cluster_centers_
label_names = ['Cluster1','Cluster2','Cluster3']

# Define the colors for each label using the 'brg' colormap
colors = ['r', '#90EE90', 'b']

for label in range(len(label_names)):
    cluster_data = data1[labels == label]
    plt.scatter(cluster_data['OG_CRIMES'], cluster_data['TL_CRIMES'], c=colors[label], label=label_names[label])

plt.scatter(centroids[:,0], centroids[:,1], marker='x', s=150, c='black', label='Centroids')
plt.xlabel('London Overground',fontweight='bold')
plt.ylabel('London Tramlink',fontweight='bold')
plt.title('K-Means Clustering of Lower Crime Modes for k=3',fontweight='bold')
plt.legend(loc='upper right',fontsize='medium')
plt.show()